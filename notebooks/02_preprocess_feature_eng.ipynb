{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d90a3b-d982-4d28-8870-0f7d7837fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HPi5_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>February 13, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 5, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 27, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
       "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 22, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 24, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
       "1  Trump drops Steve Bannon from National Securit...   \n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
       "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
       "4  Donald Trump heads for Scotland to reopen a go...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
       "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
       "3  On Monday, Donald Trump once again embarrassed...          News   \n",
       "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
       "\n",
       "                  date  label  \n",
       "0    February 13, 2017      1  \n",
       "1       April 5, 2017       0  \n",
       "2  September 27, 2017       0  \n",
       "3         May 22, 2017      1  \n",
       "4       June 24, 2016       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # for regular expressions\n",
    "import nltk\n",
    "import spacy\n",
    "import joblib\n",
    "from tqdm.auto import tqdm # for progress bars\n",
    "\n",
    "# Load the spacy model\n",
    "nltk.download('punkt_tab')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# Load the dataset from the interim folder\n",
    "df = pd.read_csv('../data/interim/news_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab364ed3-7b2f-4ec9-a489-4dab32d3d713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  label\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...      1\n",
       "1  Trump drops Steve Bannon from National Securit...      0\n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...      0\n",
       "3   OOPS: Trump Just Accidentally Confirmed He Le...      1\n",
       "4  Donald Trump heads for Scotland to reopen a go...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle potential missing values just in case, filling them with an empty string\n",
    "df['title'] = df['title'].fillna('')\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# Combine title and text into a new 'full_text' column\n",
    "df['full_text'] = df['title'] + \" \" + df['text']\n",
    "df[['full_text', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb1e937-337b-4b71-90a4-81ff9cf9f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of English stopwords\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses a single text string.\n",
    "    \"\"\"\n",
    "    # 1. Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "\n",
    "    # 3. Tokenize the text into words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # 4. Lemmatize and remove stopwords\n",
    "    # We use Spacy for more accurate lemmatization\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if token.text not in stop_words]\n",
    "\n",
    "    # 5. Join tokens back into a single string\n",
    "    processed_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff63f2b5-2f0e-437f-b8e9-88bff22d4b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text preprocessing on the 'full_text' column...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab593876f534717926e6622b2da21b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPi5_\\AppData\\Local\\Temp\\ipykernel_4088\\3201039979.py:12: DeprecationWarning: 'count' is passed as positional argument\n",
      "  text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>ben stein call th circuit court commit coup dt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>trump drop steve bannon national security coun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>puerto rico expect we lift jones act shipping ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
       "      <td>oops trump accidentally confirm leak israeli i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>donald trump head scotland reopen golf resort ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
       "1  Trump drops Steve Bannon from National Securit...   \n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
       "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
       "4  Donald Trump heads for Scotland to reopen a go...   \n",
       "\n",
       "                                          clean_text  label  \n",
       "0  ben stein call th circuit court commit coup dt...      1  \n",
       "1  trump drop steve bannon national security coun...      0  \n",
       "2  puerto rico expect we lift jones act shipping ...      0  \n",
       "3  oops trump accidentally confirm leak israeli i...      1  \n",
       "4  donald trump head scotland reopen golf resort ...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This lets us use .progress_apply() which shows a progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"Starting text preprocessing on the 'full_text' column...\")\n",
    "# Apply the function. This will take some time.\n",
    "df['clean_text'] = df['full_text'].progress_apply(preprocess_text)\n",
    "print(\"Preprocessing complete.\")\n",
    "\n",
    "# View the original vs. cleaned text\n",
    "df[['full_text', 'clean_text', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be7e645c-90d5-45c9-b1ed-1e7865305e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 35918\n",
      "Test set size: 8980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define our features (X) and target (y)\n",
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2,       # 20% of data will be for testing\n",
    "    random_state=42,     # Ensures the split is the same every time\n",
    "    stratify=y           # IMPORTANT: Keeps the same % of fake/real in both sets\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4bbf01-aad1-43a5-9cd9-751d93225ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF on training data...\n",
      "Transforming test data...\n",
      "TF-IDF vectorization complete.\n",
      "Shape of training TF-IDF matrix: (35918, 10000)\n",
      "Shape of testing TF-IDF matrix: (8980, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  # Consider both single words and two-word phrases (bigrams)\n",
    "    max_features=10000,  # Limit the vocabulary size to the top 10,000 features\n",
    "    min_df=5,            # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.8           # Ignore terms that appear in more than 80% of documents\n",
    ")\n",
    "\n",
    "# --- IMPORTANT ---\n",
    "# Fit the vectorizer and transform the TRAINING data\n",
    "print(\"Fitting TF-IDF on training data...\")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# ONLY transform the TEST data\n",
    "print(\"Transforming test data...\")\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF vectorization complete.\")\n",
    "print(f\"Shape of training TF-IDF matrix: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape of testing TF-IDF matrix: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466ef78a-9776-4b87-b46d-9adec159eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import save_npz\n",
    "import pandas as pd\n",
    "\n",
    "# Save the TF-IDF matrices\n",
    "save_npz('../data/processed/X_train_tfidf.npz', X_train_tfidf)\n",
    "save_npz('../data/processed/X_test_tfidf.npz', X_test_tfidf)\n",
    "\n",
    "# Save the labels\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "\n",
    "print(\"Processed data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50e190-183a-4726-b33c-64264aee169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(tfidf_vectorizer, '../models/tfidf_vectorizer.joblib')\n",
    "\n",
    "print(\"Vectorizer saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
